{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBased():\n",
    "    # 初始化参数\n",
    "    def __init__(self):\n",
    "        # 推荐与用户喜好最相似的10部电影\n",
    "        self.n_rec_movies = 10\n",
    "        \n",
    "        # 训练集与测试集\n",
    "        self.ratio = 0.7\n",
    "        self.train = {}\n",
    "        self.test = {}\n",
    "        \n",
    "        # 电影元数据\n",
    "        self.movies = 0\n",
    "        self.tags = 0\n",
    "        self.movie_count = 0\n",
    "        \n",
    "        # 电影评分权重计算参数\n",
    "        self.quantile = 0.95\n",
    "        self.m = 0\n",
    "        self.c = 0\n",
    "        \n",
    "        # 电影相似度矩阵\n",
    "        self.cosine_sim = 0\n",
    "        \n",
    "        print('Recommended movies number = %d' % self.n_rec_movies)\n",
    "        \n",
    "        \n",
    "    # 载入数据    \n",
    "    def load_file(self, filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                yield line.strip('\\r\\n')\n",
    "        print(\"Succeed in loading file!\")\n",
    "        \n",
    "    \n",
    "    # 划分训练、测试数据集\n",
    "    def get_dataset(self, filepath):\n",
    "        train_len = 0\n",
    "        test_len  = 0\n",
    "        for line in self.load_file(filepath):\n",
    "            user, movieId, rating, timestamp = line.split(',')\n",
    "            if random.random() < self.ratio:\n",
    "                self.train.setdefault(user,[])\n",
    "                self.train[user].append(movieId)\n",
    "                train_len += 1\n",
    "            else:\n",
    "                self.test.setdefault(user, [])\n",
    "                self.test[user].append(movieId)\n",
    "                test_len += 1\n",
    "        print('Succeed in spliting training dataset and testing dataset!')\n",
    "        print('Training dataset = %d' % train_len)\n",
    "        print('Testing dataset = %d' % test_len)\n",
    "\n",
    "    \n",
    "    # 处理电影title, \n",
    "    # “Shining, The (1980)”→“The Shining”\n",
    "    # \"Toy Story (1995)\"→“Toy Story\"\n",
    "    def reset_title(self, x):\n",
    "        if ',' in x:\n",
    "            return ' '.join(x[:-7].split(',')[::-1]).strip()\n",
    "        else:\n",
    "            return x[:-7]\n",
    "        \n",
    "    \n",
    "    # 计算评分权重\n",
    "    def get_weight(self, x):\n",
    "        v = x['rate_count']\n",
    "        r = x['avg_rating']\n",
    "        return (v / (v + self.m) * r + self.m / (v + self.m) * self.c)\n",
    "    \n",
    "    \n",
    "    # 计算电影评分（被评次数、平均评分、评分权重）\n",
    "    def movie_metadata(self, movies_csv, ratings_csv):\n",
    "        print(\"Preparing movie metadate...\")\n",
    "        avg_rating = dict()\n",
    "        rate_count = dict()\n",
    "        self.movies = pd.read_csv(movies_csv)\n",
    "        ratings = pd.read_csv(ratings_csv)\n",
    "        self.movie_count = len(self.movies)\n",
    "        \n",
    "        self.movies['year'] = self.movies['title'].apply(lambda x: x[:-5:-1])\n",
    "        self.movies['title'] = self.movies['title'].apply(self.reset_title)\n",
    "        self.movies['genres'] = self.movies['genres'].apply(lambda x: x.split('|'))\n",
    "        \n",
    "        for movieId in set(ratings['movieId']):\n",
    "            sum_rating = sum(ratings[ratings['movieId'] == movieId]['rating'])\n",
    "            num_rating = len(ratings[ratings['movieId'] == movieId]['rating'])\n",
    "            avg_rating[movieId] = round(sum_rating / num_rating, 2)\n",
    "            rate_count[movieId] = num_rating\n",
    "            \n",
    "        r_cnt = pd.DataFrame(rate_count, index=[0]).transpose().reset_index()\n",
    "        r_cnt.columns = ['movieId', 'rate_count']\n",
    "        \n",
    "        r_avg = pd.DataFrame(avg_rating, index=[0]).transpose().reset_index()\n",
    "        r_avg.columns = ['movieId', 'avg_rating']\n",
    "        \n",
    "        r_cnt_avg = pd.merge(r_cnt, r_avg, how='left', on='movieId')\n",
    "        self.movies = pd.merge(self.movies, r_cnt_avg, how='left', on='movieId')\n",
    "        \n",
    "        self.m = self.movies['rate_count'].quantile(self.quantile)\n",
    "        self.movies = self.movies[self.movies['rate_count'] >= self.m]\n",
    "        self.c = self.movies['avg_rating'].mean()\n",
    "        \n",
    "        self.movies['r_weight'] = self.movies.apply(self.get_weight, axis=1)\n",
    "        self.movies = self.movies.sort_values('r_weight', ascending=False)\n",
    "        \n",
    "        print(\"Succeed in preparing Movie metadate!\")\n",
    "    \n",
    "    \n",
    "    # 提取电影标签\n",
    "    def tag_extraction(self, tag):\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        d = dict()\n",
    "        for m_id in set(tag['movieId']):\n",
    "            m_tag = tag[tag['movieId'] == m_id]['tag']\n",
    "            d[m_id] = str(list(set([stemmer.stem(i) for i in m_tag])))\n",
    "        return d\n",
    "    \n",
    "    \n",
    "    # 计算电影相似度\n",
    "    def cal_movie_sim(self, tags_csv):\n",
    "        self.tags = pd.read_csv(tags_csv)\n",
    "        s = self.tags[['movieId','tag']]\n",
    "        m_tags = pd.DataFrame(self.tag_extraction(s), index=[0]).transpose().reset_index()\n",
    "        m_tags.columns = ['movieId','tag']\n",
    "        m_tags['tag'] = m_tags['tag'].apply(literal_eval)\n",
    "        self.movies = self.movies.merge(m_tags, how='left', on='movieId')\n",
    "        self.movies['tag'] = self.movies['tag'].apply(lambda x: [] if str(x) == 'nan' else x)\n",
    "        self.movies['description'] = self.movies['genres'] + self.movies['tag']\n",
    "        self.movies['description'] = self.movies['description'].apply(lambda x: ' '.join(x))\n",
    "        \n",
    "        tf = TfidfVectorizer(analyzer='word',ngram_range=(1,2),min_df=0,stop_words='english')\n",
    "        tfidf_matrix = tf.fit_transform(self.movies['description'])\n",
    "        self.cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)    \n",
    "        \n",
    "        \n",
    "    # 根据用户历史行为筛选出相似电影合集，按照评分权重排序选出前10部电影\n",
    "    def recommend(self, user):\n",
    "        n = self.n_rec_movies\n",
    "        rec = set()\n",
    "        columns = self.movies['movieId']\n",
    "        index = self.movies['movieId']\n",
    "        m_sim = pd.DataFrame(self.cosine_sim,columns=columns,index=index)\n",
    "        watched = [int(i) for i in self.train[user]]\n",
    "        for movie in watched:\n",
    "            if movie in m_sim.columns:\n",
    "                top_5 = list(m_sim.sort_values(movie,ascending=False).index[1:6])\n",
    "                for i in top_5:\n",
    "                    if i not in watched:\n",
    "                        rec.add(i)\n",
    "        rec_df = pd.DataFrame(list(rec), columns=['movieId'])\n",
    "        rec_movies = rec_df.merge(self.movies,how='left',on='movieId')\n",
    "        rec_movies = rec_movies.sort_values('avg_rating',ascending=False)\n",
    "        top_movies = rec_movies[['movieId','title']][:n]\n",
    "        return top_movies\n",
    "\n",
    "    \n",
    "    # 产生推荐并通过准确率、召回率和覆盖率进行评估\n",
    "    def evaluate(self):\n",
    "        print(\"Evaluation start...\")\n",
    "        n = self.n_rec_movies\n",
    "        # 准确率和召回率\n",
    "        hit = 0\n",
    "        rec_count = 0\n",
    "        test_count = 0\n",
    "        # 覆盖率\n",
    "        all_rec_movies = set()\n",
    "        \n",
    "        for user in self.train:\n",
    "            test_movies = self.test[user]\n",
    "            top_movies = self.recommend(user)\n",
    "            rec_movies = list(set(top_movies['movieId']))\n",
    "            for movie in rec_movies:\n",
    "                if str(movie) in test_movies:\n",
    "                    hit += 1\n",
    "                all_rec_movies.add(movie)\n",
    "            rec_count += n\n",
    "            test_count += len(test_movies)\n",
    "            \n",
    "        precision = hit / rec_count\n",
    "        recall    = hit / test_count\n",
    "        coverate  = len(all_rec_movies) / self.movie_count\n",
    "        \n",
    "        result = (precision, recall, coverate)\n",
    "        print('Precision = %.4f\\nRecall = %.4f\\nCoverage = %.4f' % result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies number = 10\n",
      "Succeed in loading file!\n",
      "Succeed in spliting training dataset and testing dataset!\n",
      "Training dataset = 70489\n",
      "Testing dataset = 30347\n",
      "Preparing movie metadate...\n",
      "Succeed in preparing Movie metadate!\n",
      "for user 3, 10 movies are recommended as follows:\n",
      "    movieId                                         title\n",
      "16    81845                             The King's Speech\n",
      "6       778                                 Trainspotting\n",
      "17      953                         It's a Wonderful Life\n",
      "5     81834  Harry Potter and the Deathly Hallows: Part 1\n",
      "14     2997                          Being John Malkovich\n",
      "1      4034                                       Traffic\n",
      "12    59315                                      Iron Man\n",
      "8      2797                                           Big\n",
      "15     6870                                  Mystic River\n",
      "13     8784                                  Garden State\n",
      "Evaluation start...\n",
      "Precision = 0.1441\n",
      "Recall = 0.0290\n",
      "Coverage = 0.0239\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    movies_file = './input_data/small/movies.csv'\n",
    "    ratings_file = './input_data/small/ratings.csv'\n",
    "    tags_file = './input_data/small/tags.csv'\n",
    "    user = '3'\n",
    "    engine = ContentBased()\n",
    "    engine.get_dataset(ratings_file)\n",
    "    engine.movie_metadata(movies_file,ratings_file)\n",
    "    engine.cal_movie_sim(tags_file)\n",
    "    print(\"for user {:}, 10 movies are recommended as follows:\".format(user))\n",
    "    print(engine.recommend(user))\n",
    "    engine.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
